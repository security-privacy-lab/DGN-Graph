import json
import os
import torch
from torch_geometric.data import Data
from sklearn.model_selection import KFold

def save_graph(graph, output_dir, max_feature_dim=None):
    os.makedirs(output_dir, exist_ok=True)

    # Ensure node features are uniform and padded if necessary
    if all('feature' not in node for node in graph['nodes']):
        num_nodes = len(graph['nodes'])
        feature_dim = num_nodes  # Adjust as necessary
        print("Node features missing. Initializing dummy features.")
        for node in graph['nodes']:
            node['feature'] = [0] * feature_dim  # Example: Zero vector

    # Extract node features and ensure uniform dimension
    if max_feature_dim is None:
        max_feature_dim = max(len(node['feature']) for node in graph['nodes'])
    
    node_features = []
    for node in graph['nodes']:
        feature = node['feature']
        if len(feature) < max_feature_dim:
            feature += [0] * (max_feature_dim - len(feature))  # Padding with zeros
        elif len(feature) > max_feature_dim:
            feature = feature[:max_feature_dim]  # Truncate if longer
        node_features.append(feature)
    node_features = torch.tensor(node_features, dtype=torch.float)

    # Check if edges are present, initialize as empty list if missing
    if 'edges' not in graph:
        print("Edges missing. Initializing empty edges.")
        graph['edges'] = []

    # Extract edge index
    edge_index = []
    for edge in graph['edges']:
        edge_index.append([edge['source'], edge['target']])
    if not edge_index:
        edge_index = torch.empty((2, 0), dtype=torch.long)  # Empty edge index
    else:
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

    # Extract labels
    labels = [node['label'] for node in graph['nodes']]
    labels = torch.tensor(labels, dtype=torch.long)

    # Create Data object
    data = Data(x=node_features, edge_index=edge_index, y=labels)

    # Save the Data object to a file
    torch.save(data, os.path.join(output_dir, "data.pt"))

def generate_id_map(graph):
    id_map = {}
    index = 0
    for node in graph["nodes"]:
        id_map[node["id"]] = index
        index += 1
    return id_map

def generate_class_map(graph):
    class_map = {}
    for node in graph["nodes"]:
        class_map[node["id"]] = node["label"]
    return class_map

def save_id_map(id_map, output_dir):
    with open(os.path.join(output_dir, "id_map.json"), "w") as f:
        json.dump(id_map, f)

def save_class_map(class_map, output_dir):
    with open(os.path.join(output_dir, "class_map.json"), "w") as f:
        json.dump(class_map, f)

if __name__ == "__main__":
    # Load the list of graphs
    with open("graph_creation/processed_data/pygraphs.json", "r") as f:
        graph_lst = json.load(f)["graphs"]

    # Perform cross-validation at the graph level with KFold
    n_splits = 5
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    # Iterate over the splits generated by KFold
    for fold_idx, (train_index, test_index) in enumerate(kf.split(graph_lst)):
        train_graphs = [graph_lst[i] for i in train_index]
        test_graphs = [graph_lst[i] for i in test_index]

        # Process each training graph
        for idx, graph in enumerate(train_graphs):
            output_dir = f"graph_creation/processed_data/fold_{fold_idx + 1}/train/{idx}/"
            save_graph(graph, output_dir)
            id_map = generate_id_map(graph)
            class_map = generate_class_map(graph)
            save_id_map(id_map, output_dir)
            save_class_map(class_map, output_dir)

        # Process each testing graph
        for idx, graph in enumerate(test_graphs):
            output_dir = f"graph_creation/processed_data/fold_{fold_idx + 1}/test/{idx}/"
            save_graph(graph, output_dir)
            id_map = generate_id_map(graph)
            class_map = generate_class_map(graph)
            save_id_map(id_map, output_dir)
            save_class_map(class_map, output_dir)
