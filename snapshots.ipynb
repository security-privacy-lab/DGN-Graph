{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snapshots Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One: Graph Creation / Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we have to import our data (in the case of using other datasets this is probably the biggest section to edit.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"snapshot_data\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json.gz\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "\n",
    "            with gzip.open(file_path, \"rt\") as f:\n",
    "                for line in f:\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        merged_dataset.append(data)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error parsing line in {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we look at the first few entries to understand what we want to use in our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': '2019-09-24T10:02:46.358-04:00', 'id': '2aa91c3d-9253-4cb2-8585-1eb43db675ed', 'hostname': 'SysClient0968.systemia.com', 'objectID': 'c4d4e50c-1075-4a35-8331-662db77dc65e', 'object': 'FLOW', 'action': 'INFO', 'actorID': 'e27d5804-74e7-454e-af19-b4501c0e99d2', 'pid': 6012, 'ppid': 6004, 'tid': -1, 'principal': 'SYSTEMIACOM\\\\fmarisei', 'properties': {'acuity_level': '1', 'bro_uid': 'CJn14UbY78b0N89Sl', 'dest_ip': '98.61.14.5', 'dest_port': '80', 'direction': 'outbound', 'image_path': '\\\\\\\\?\\\\C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe', 'l4protocol': '6', 'src_ip': '142.20.59.201', 'src_port': '49789'}}, {'timestamp': '2019-09-24T10:02:46.37-04:00', 'id': 'cabf9e99-b3ed-4834-9b54-8f4a0e7bfd25', 'hostname': 'SysClient0968.systemia.com', 'objectID': '515eb9a9-7e63-4821-bc78-a6cde6dc8716', 'object': 'FLOW', 'action': 'INFO', 'actorID': 'e27d5804-74e7-454e-af19-b4501c0e99d2', 'pid': 6012, 'ppid': 6004, 'tid': -1, 'principal': 'SYSTEMIACOM\\\\fmarisei', 'properties': {'acuity_level': '1', 'bro_uid': 'ChjTcn2dacvfCJ5Dza', 'dest_ip': '98.61.14.5', 'dest_port': '443', 'direction': 'outbound', 'image_path': '\\\\\\\\?\\\\C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe', 'l4protocol': '6', 'src_ip': '142.20.59.201', 'src_port': '49790'}}, {'timestamp': '2019-09-24T10:02:46.559-04:00', 'id': '34b3cafc-5923-40ac-b383-8e476ccdd2e8', 'hostname': 'SysClient0968.systemia.com', 'objectID': '7a56cc5f-feae-4e46-a38a-65375c5f6502', 'object': 'FLOW', 'action': 'INFO', 'actorID': 'e27d5804-74e7-454e-af19-b4501c0e99d2', 'pid': 6012, 'ppid': 6004, 'tid': -1, 'principal': 'SYSTEMIACOM\\\\fmarisei', 'properties': {'acuity_level': '1', 'bro_uid': 'CW1Nvu4W74fs7qP4d8', 'dest_ip': '98.61.14.5', 'dest_port': '443', 'direction': 'outbound', 'image_path': '\\\\\\\\?\\\\C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe', 'l4protocol': '6', 'src_ip': '142.20.59.201', 'src_port': '49793'}}, {'timestamp': '2019-09-24T10:02:46.561-04:00', 'id': 'f68b8f6b-0956-4f27-ab5f-f64decc4c585', 'hostname': 'SysClient0968.systemia.com', 'objectID': '2a8c6044-7c74-44d1-89b2-b416b64363d5', 'object': 'FLOW', 'action': 'INFO', 'actorID': 'e27d5804-74e7-454e-af19-b4501c0e99d2', 'pid': 6012, 'ppid': 6004, 'tid': -1, 'principal': 'SYSTEMIACOM\\\\fmarisei', 'properties': {'acuity_level': '1', 'bro_uid': 'Cwvlh92ZLjuaqudDm4', 'dest_ip': '98.61.14.5', 'dest_port': '443', 'direction': 'outbound', 'image_path': '\\\\\\\\?\\\\C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe', 'l4protocol': '6', 'src_ip': '142.20.59.201', 'src_port': '49794'}}, {'timestamp': '2019-09-24T10:02:46.613-04:00', 'id': 'd58b1b65-3c14-40d2-b0ec-2903d1e2c836', 'hostname': 'SysClient0968.systemia.com', 'objectID': 'a5686615-926b-4657-a70c-61e9cd370494', 'object': 'FLOW', 'action': 'INFO', 'actorID': 'e27d5804-74e7-454e-af19-b4501c0e99d2', 'pid': 6012, 'ppid': 6004, 'tid': -1, 'principal': 'SYSTEMIACOM\\\\fmarisei', 'properties': {'acuity_level': '1', 'bro_uid': 'CBcfqw46pn2zqxUK2a', 'dest_ip': '98.61.14.5', 'dest_port': '443', 'direction': 'outbound', 'image_path': '\\\\\\\\?\\\\C:\\\\Program Files (x86)\\\\Mozilla Firefox\\\\firefox.exe', 'l4protocol': '6', 'src_ip': '142.20.59.201', 'src_port': '49795'}}]\n"
     ]
    }
   ],
   "source": [
    "print(merged_dataset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we establish arrays for nodes, edges, and timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_nodes = {}\n",
    "node_idx = 0\n",
    "\n",
    "edges = []\n",
    "timestamps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(For this particular dataset, the timestamps are specific and non-standard enough where isoparse has to be used.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(timestamp):\n",
    "    try:\n",
    "        return parser.isoparse(timestamp).timestamp()\n",
    "    except ValueError:\n",
    "        print(f\"Failed to parse timestamp: {timestamp}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otherwise, we set up a graph structure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in merged_dataset:\n",
    "    src_ip = entry['properties']['src_ip']\n",
    "    dest_ip = entry['properties']['dest_ip']\n",
    "    timestamp = entry['timestamp']\n",
    "    \n",
    "    # Assign a node index for each new IP\n",
    "    if src_ip not in ip_nodes:\n",
    "        ip_nodes[src_ip] = node_idx\n",
    "        node_idx += 1\n",
    "    if dest_ip not in ip_nodes:\n",
    "        ip_nodes[dest_ip] = node_idx\n",
    "        node_idx += 1\n",
    "    \n",
    "    # Add an edge (src -> dest)\n",
    "    edges.append([ip_nodes[src_ip], ip_nodes[dest_ip]])\n",
    "    \n",
    "    parsed_time = parse_timestamp(timestamp)\n",
    "    if parsed_time is not None:\n",
    "        timestamps.append(parsed_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And make the graph itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4273457], edge_attr=[4273457, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  \n",
    "edge_attr = torch.tensor(timestamps, dtype=torch.float).unsqueeze(1)  \n",
    "\n",
    "graph = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Snapshot Brainstorming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are going to first figure out what the best delta for creating snapshots is. This is definitely a subjective question, but we can do a little bit of brainstorming to narrow it down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can calculate the range of the time for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest timestamp: 2019-09-24 10:02:30.039000-04:00\n",
      "Latest timestamp: 2019-09-25 09:04:49.419000-04:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "timestamps = [entry['timestamp'] for entry in merged_dataset]\n",
    "\n",
    "timestamps = [datetime.strptime(ts, '%Y-%m-%dT%H:%M:%S.%f%z') if '.' in ts else datetime.strptime(ts, '%Y-%m-%dT%H:%M:%S%z') for ts in timestamps]\n",
    "\n",
    "min_timestamp = min(timestamps)\n",
    "max_timestamp = max(timestamps)\n",
    "\n",
    "print(\"Earliest timestamp:\", min_timestamp)\n",
    "print(\"Latest timestamp:\", max_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have data over about a days worth of data, so the best first guess would be to get data for every hour, which we can check with the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: 23:02:19.380000\n",
      "Number of snapshots: 23\n"
     ]
    }
   ],
   "source": [
    "time_range = max_timestamp - min_timestamp\n",
    "\n",
    "t = timedelta(hours=1)\n",
    "\n",
    "num_snapshots = time_range // t\n",
    "\n",
    "print(f\"Time range: {time_range}\")\n",
    "print(f\"Number of snapshots: {num_snapshots}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demonstrates we have 23 snapshots worth of data, which may either be perfect, or may be too broad or specific. Let's check with half hours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time range: 23:02:19.380000\n",
      "Number of snapshots: 46\n"
     ]
    }
   ],
   "source": [
    "time_range = max_timestamp - min_timestamp\n",
    "\n",
    "t = timedelta(hours=.5)\n",
    "\n",
    "num_snapshots = time_range // t\n",
    "\n",
    "print(f\"Time range: {time_range}\")\n",
    "print(f\"Number of snapshots: {num_snapshots}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going with half-hour intervals gets us more snapshots, which may be better or worse. In our experimental case here, we can go with the safe choice of having a time delta of 1 hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Snapshot Graph Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the delta hopefully determined, we can now create our snapshot graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, use the timestamp range and delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = min_timestamp\n",
    "end_time = max_timestamp    \n",
    "time_delta = timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the snapshots list and note the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = []\n",
    "current_time = start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And create a loop that will go through every hour and create a snapshot graph (no need to go into detail on how a graph is made, just carry over how it was done earlier and you are good to go.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "while current_time < end_time:\n",
    "    next_time = current_time + time_delta\n",
    "    \n",
    "    snapshot_data = [entry for entry in merged_dataset if current_time <= datetime.fromisoformat(entry['timestamp']) < next_time]\n",
    "    \n",
    "    ip_nodes = {}\n",
    "    edges = []\n",
    "    timestamps = []\n",
    "\n",
    "    for entry in snapshot_data:\n",
    "        src_ip = entry['properties']['src_ip']\n",
    "        dest_ip = entry['properties']['dest_ip']\n",
    "        timestamp = entry['timestamp']\n",
    "\n",
    "        if src_ip not in ip_nodes:\n",
    "            ip_nodes[src_ip] = len(ip_nodes)\n",
    "        if dest_ip not in ip_nodes:\n",
    "            ip_nodes[dest_ip] = len(ip_nodes)\n",
    "\n",
    "        edges.append([ip_nodes[src_ip], ip_nodes[dest_ip]])\n",
    "\n",
    "    \n",
    "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(timestamps, dtype=torch.float)\n",
    "\n",
    "    snapshot = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "    snapshots.append(snapshot)\n",
    "\n",
    "    current_time = next_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot 1\n",
      "Snapshot 2\n",
      "Snapshot 3\n",
      "Snapshot 4\n",
      "Snapshot 5\n",
      "Snapshot 6\n",
      "Snapshot 7\n",
      "Snapshot 8\n",
      "Snapshot 9\n",
      "Snapshot 10\n",
      "Snapshot 11\n",
      "Snapshot 12\n",
      "Snapshot 13\n",
      "Snapshot 14\n",
      "Snapshot 15\n",
      "Snapshot 16\n",
      "Snapshot 17\n",
      "Snapshot 18\n",
      "Snapshot 19\n",
      "Snapshot 20\n",
      "Snapshot 21\n",
      "Snapshot 22\n",
      "Snapshot 23\n",
      "Snapshot 24\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(snapshots)):\n",
    "    print(f\"Snapshot {i+1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our snapshot graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapshots",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
